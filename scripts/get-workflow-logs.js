#!/usr/bin/env node

/**
 * è·å– GitHub Actions å·¥ä½œæµç¨‹è¿è¡Œæ—¥å¿—
 * å¢å¼ºç‰ˆï¼šæ”¯æŒ ZIP æ—¥å¿—è§£æå’Œé”™è¯¯æå–
 */

import https from 'https';
import fs from 'fs';
import { createWriteStream } from 'fs';
import { pipeline } from 'stream/promises';
import { createUnzip } from 'zlib';
import { Readable } from 'stream';

const CONFIG = {
  owner: 'hello--world',
  repo: 'winunlock',
  runId: process.argv[2] || '19604278709',
  githubToken: process.env.GITHUB_TOKEN || '',
};

/**
 * GitHub API è¯·æ±‚ï¼ˆæ”¯æŒäºŒè¿›åˆ¶æ•°æ®ï¼‰
 */
function githubApiRequest(endpoint, options = {}) {
  return new Promise((resolve, reject) => {
    const requestOptions = {
      hostname: 'api.github.com',
      path: endpoint,
      method: 'GET',
      headers: {
        'User-Agent': 'Workflow-Log-Script',
        'Accept': options.binary ? 'application/vnd.github.v3.raw' : 'application/vnd.github.v3+json',
        ...(CONFIG.githubToken && { 'Authorization': `token ${CONFIG.githubToken}` }),
      },
    };

    const req = https.request(requestOptions, (res) => {
      const chunks = [];
      res.on('data', (chunk) => { chunks.push(chunk); });
      res.on('end', () => {
        const data = options.binary ? Buffer.concat(chunks) : Buffer.concat(chunks).toString('utf-8');
        try {
          if (res.statusCode >= 200 && res.statusCode < 300) {
            resolve(data);
          } else {
            if (options.binary) {
              reject(new Error(`GitHub API error: ${res.statusCode}`));
            } else {
              const json = JSON.parse(data);
              reject(new Error(`GitHub API error: ${res.statusCode} - ${JSON.stringify(json)}`));
            }
          }
        } catch (e) {
          // å¯èƒ½æ˜¯æ–‡æœ¬å“åº”
          if (res.statusCode >= 200 && res.statusCode < 300) {
            resolve(data);
          } else {
            reject(new Error(`Failed: ${res.statusCode} - ${data.toString().substring(0, 200)}`));
          }
        }
      });
    });

    req.on('error', reject);
    req.end();
  });
}

/**
 * è§£å‹ ZIP æ ¼å¼çš„æ—¥å¿—æ•°æ®
 * æ³¨æ„ï¼šGitHub Actions æ—¥å¿—æ˜¯ ZIP æ ¼å¼ï¼Œä½† Node.js å†…ç½®åº“ä¸æ”¯æŒ ZIP
 * è¿™é‡Œå°è¯• gzip è§£å‹ï¼ˆæŸäº›æƒ…å†µä¸‹å¯èƒ½æ˜¯ gzipï¼‰ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•ä½œä¸ºæ–‡æœ¬è¯»å–
 */
async function extractZipLogs(zipBuffer) {
  try {
    // æ£€æŸ¥æ˜¯å¦æ˜¯ ZIP æ–‡ä»¶ï¼ˆZIP æ–‡ä»¶ä»¥ PK å¼€å¤´ï¼‰
    if (zipBuffer.length >= 2 && zipBuffer[0] === 0x50 && zipBuffer[1] === 0x4B) {
      // è¿™æ˜¯ ZIP æ–‡ä»¶ï¼Œä½† Node.js å†…ç½®åº“ä¸æ”¯æŒ ZIP
      // è¿”å›æç¤ºä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨å¤–éƒ¨å·¥å…·æˆ–åº“
      console.warn('âš ï¸  æ£€æµ‹åˆ° ZIP æ ¼å¼æ—¥å¿—ï¼Œä½†éœ€è¦é¢å¤–åº“æ¥è§£å‹');
      console.warn('   å»ºè®®ï¼šå®‰è£… adm-zip æˆ–ä½¿ç”¨ GitHub API çš„æ–‡æœ¬æ ¼å¼');
      // å°è¯•æå– ZIP ä¸­çš„æ–‡æœ¬å†…å®¹ï¼ˆç®€å•å°è¯•ï¼‰
      // å¯¹äº GitHub Actionsï¼Œæ—¥å¿—é€šå¸¸åœ¨ ZIP çš„æŸä¸ªæ–‡ä»¶ä¸­
      // è¿™é‡Œè¿”å›ä¸€ä¸ªæç¤ºï¼Œå®é™…ä½¿ç”¨æ—¶å¯èƒ½éœ€è¦å®‰è£… adm-zip
      return `[ZIP æ ¼å¼æ—¥å¿—ï¼Œéœ€è¦è§£å‹]\næ–‡ä»¶å¤§å°: ${zipBuffer.length} å­—èŠ‚\næç¤º: è¯·ä½¿ç”¨ GitHub Actions ç½‘é¡µæŸ¥çœ‹å®Œæ•´æ—¥å¿—ï¼Œæˆ–å®‰è£… adm-zip åº“æ¥è§£å‹`;
    }
    
    // å°è¯• gzip è§£å‹ï¼ˆæŸäº›æƒ…å†µä¸‹å¯èƒ½æ˜¯ gzipï¼‰
    try {
      const unzip = createUnzip();
      const chunks = [];
      const stream = Readable.from([zipBuffer]);
      
      stream.pipe(unzip);
      
      return new Promise((resolve, reject) => {
        unzip.on('data', (chunk) => chunks.push(chunk));
        unzip.on('end', () => {
          resolve(Buffer.concat(chunks).toString('utf-8'));
        });
        unzip.on('error', (err) => {
          // å¦‚æœä¸æ˜¯ gzipï¼Œå°è¯•ä½œä¸ºæ–‡æœ¬è¯»å–
          const text = zipBuffer.toString('utf-8');
          // æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ UTF-8 æ–‡æœ¬
          if (text.length > 0 && !text.includes('\0')) {
            resolve(text);
          } else {
            resolve(`[æ— æ³•è§£æçš„äºŒè¿›åˆ¶æ•°æ®]\nå¤§å°: ${zipBuffer.length} å­—èŠ‚\næç¤º: è¿™å¯èƒ½æ˜¯ ZIP æ ¼å¼ï¼Œéœ€è¦è§£å‹`);
          }
        });
      });
    } catch (e) {
      // å¦‚æœè§£å‹å¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½œä¸ºæ–‡æœ¬è¯»å–
      const text = zipBuffer.toString('utf-8');
      if (text.length > 0 && !text.includes('\0')) {
        return text;
      } else {
        return `[æ— æ³•è§£æçš„äºŒè¿›åˆ¶æ•°æ®]\nå¤§å°: ${zipBuffer.length} å­—èŠ‚`;
      }
    }
  } catch (error) {
    // æœ€åçš„ fallback
    const text = zipBuffer.toString('utf-8');
    return text.length > 0 ? text : `[é”™è¯¯: ${error.message}]`;
  }
}

/**
 * è·å–å•ä¸ª job çš„æ—¥å¿—å†…å®¹
 */
async function getJobLogs(job) {
  if (!job.logs_url) {
    return null;
  }

  try {
    const endpoint = job.logs_url.replace('https://api.github.com', '');
    const logData = await githubApiRequest(endpoint, { binary: true });
    
    // å°è¯•è§£å‹æ—¥å¿—
    const extractedLogs = await extractZipLogs(logData);
    return extractedLogs;
  } catch (error) {
    console.warn(`âš ï¸  æ— æ³•ä¸‹è½½ job ${job.name} çš„æ—¥å¿—: ${error.message}`);
    return null;
  }
}

/**
 * è·å–å·¥ä½œæµç¨‹è¿è¡Œçš„æ‰€æœ‰æ—¥å¿—
 * @param {string} runId - è¿è¡Œ ID
 * @param {object} options - é€‰é¡¹
 * @returns {Promise<object>} åŒ…å«æ‰€æœ‰æ—¥å¿—çš„ç»“æ„åŒ–æ•°æ®
 */
async function getWorkflowRunLogs(runId, options = {}) {
  const { 
    extractErrors = false, 
    saveToFile = false,
    onlyFailed = false 
  } = options;

  try {
    if (!runId) {
      throw new Error('runId æ˜¯å¿…éœ€çš„');
    }

    if (options.verbose !== false) {
      console.log(`ğŸ“¥ è·å–å·¥ä½œæµç¨‹è¿è¡Œ #${runId} çš„æ—¥å¿—...\n`);
    }
    
    // é¦–å…ˆè·å– jobs
    const jobsResponse = await githubApiRequest(
      `/repos/${CONFIG.owner}/${CONFIG.repo}/actions/runs/${runId}/jobs`
    );
    const jobs = JSON.parse(jobsResponse);
    
    if (!jobs.jobs || jobs.jobs.length === 0) {
      if (options.verbose !== false) {
        console.log('æœªæ‰¾åˆ° jobs');
      }
      return { jobs: [], allLogs: '', failedJobs: [] };
    }
    
    if (options.verbose !== false) {
      console.log(`æ‰¾åˆ° ${jobs.jobs.length} ä¸ª jobs:\n`);
    }
    
    const result = {
      jobs: [],
      allLogs: '',
      failedJobs: [],
      failedSteps: []
    };
    
    for (const job of jobs.jobs) {
      // å¦‚æœåªè·å–å¤±è´¥çš„ï¼Œè·³è¿‡æˆåŠŸçš„
      if (onlyFailed && job.conclusion !== 'failure') {
        continue;
      }

      const jobInfo = {
        id: job.id,
        name: job.name,
        status: job.status,
        conclusion: job.conclusion,
        steps: job.steps || [],
        logs: null
      };

      if (options.verbose !== false) {
        console.log(`\n${'='.repeat(60)}`);
        console.log(`Job: ${job.name}`);
        console.log(`çŠ¶æ€: ${job.status} (${job.conclusion || 'è¿›è¡Œä¸­'})`);
        console.log('='.repeat(60) + '\n');
      }
      
      // è·å– job çš„æ—¥å¿—
      if (job.logs_url) {
        if (options.verbose !== false) {
          console.log('ğŸ“‹ ä¸‹è½½æ—¥å¿—...\n');
        }
        
        const logs = await getJobLogs(job);
        if (logs) {
          jobInfo.logs = logs;
          result.allLogs += `\n=== Job: ${job.name} ===\n${logs}\n`;
          
          if (options.verbose !== false) {
            // æ˜¾ç¤ºæ—¥å¿—çš„å‰ 2000 å­—ç¬¦
            console.log('æ—¥å¿—å†…å®¹ï¼ˆå‰ 2000 å­—ç¬¦ï¼‰ï¼š\n');
            console.log(logs.substring(0, 2000));
            console.log('\n...\n');
          }
          
          // ä¿å­˜åˆ°æ–‡ä»¶
          if (saveToFile) {
            const logFile = `workflow-log-${runId}-${job.id}.txt`;
            fs.writeFileSync(logFile, logs);
            if (options.verbose !== false) {
              console.log(`âœ… å®Œæ•´æ—¥å¿—å·²ä¿å­˜åˆ°: ${logFile}\n`);
            }
          }
        }
      }
      
      // å¤„ç†å¤±è´¥çš„ job
      if (job.conclusion === 'failure') {
        result.failedJobs.push(jobInfo);
        
        // æ”¶é›†å¤±è´¥çš„ steps
        if (job.steps) {
          job.steps.forEach(step => {
            if (step.conclusion === 'failure') {
              result.failedSteps.push({
                jobName: job.name,
                stepName: step.name,
                stepNumber: step.number
              });
            }
          });
        }
      }
      
      // æ˜¾ç¤º steps
      if (job.steps && job.steps.length > 0 && options.verbose !== false) {
        console.log('Steps:\n');
        job.steps.forEach(step => {
          const icon = step.conclusion === 'success' ? 'âœ…' : step.conclusion === 'failure' ? 'âŒ' : 'â³';
          console.log(`  ${icon} ${step.name}`);
          console.log(`    çŠ¶æ€: ${step.status} (${step.conclusion || 'è¿›è¡Œä¸­'})`);
        });
        console.log('');
      }

      result.jobs.push(jobInfo);
    }
    
    return result;
    
  } catch (error) {
    console.error('âŒ æ— æ³•è·å–æ—¥å¿—:', error.message);
    if (error.message.includes('401') || error.message.includes('403')) {
      console.log('\nğŸ’¡ æç¤º: éœ€è¦è®¾ç½® GITHUB_TOKEN ç¯å¢ƒå˜é‡æ¥è®¿é—®æ—¥å¿—');
      console.log('   export GITHUB_TOKEN=your_token');
    }
    throw error;
  }
}

async function main() {
  if (!CONFIG.githubToken) {
    console.warn('âš ï¸  è­¦å‘Š: æœªè®¾ç½® GITHUB_TOKEN ç¯å¢ƒå˜é‡');
    console.warn('   å¯èƒ½æ— æ³•ä¸‹è½½å®Œæ•´æ—¥å¿—ï¼Œä½†å¯ä»¥æŸ¥çœ‹ GitHub ç½‘é¡µ\n');
  }
  
  const result = await getWorkflowRunLogs(CONFIG.runId, { 
    saveToFile: true,
    verbose: true 
  });
  
  if (result.failedJobs.length > 0) {
    console.log(`\nâŒ å‘ç° ${result.failedJobs.length} ä¸ªå¤±è´¥çš„ job`);
  }
  
  console.log('\nğŸ’¡ æç¤º: è¦æŸ¥çœ‹å®Œæ•´æ—¥å¿—ï¼Œè¯·è®¿é—®ï¼š');
  console.log(`   https://github.com/${CONFIG.owner}/${CONFIG.repo}/actions/runs/${CONFIG.runId}`);
  
  return result;
}

if (import.meta.url === `file://${process.argv[1]}` || process.argv[1]?.endsWith('get-workflow-logs.js')) {
  main().catch(error => {
    console.error('âŒ é”™è¯¯:', error.message);
    process.exit(1);
  });
}

export { getWorkflowRunLogs, getJobLogs };

